# KG-MM-Survey
[![Awesome](https://awesome.re/badge.svg)](https://github.com/zjukg/KG-MM-Survey) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/zjukg/KG-MM-Survey/blob/main/LICENSE)
![](https://img.shields.io/github/last-commit/zjukg/KG-MM-Survey?color=green) 
![](https://img.shields.io/badge/PRs-Welcome-red) 

![Roadmap](figures/roadmap.jpg)
> 🙌 This repository collects papers integrating Knowledge Graphs (KGs) and Multi-Modal Learning, focusing on research in two principal aspects: **KG-driven Multi-Modal (KG4MM) learning**, where KGs support multi-modal tasks, and **Multi-Modal Knowledge Graph (MM4KG)**, which extends KG studies into the MMKG realm.

😎 Welcome to recommend missing papers through **`Adding Issues`** or **`Pull Requests`**. 




## 🔔 News
- **`2023-11` We preprint our Survey [Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey]()  [[`Repo`](https://github.com/zjukg/KG-MM-Survey)].**

   
## 📜 Content
![Task](figures/task.jpg)

- [KG-MM-Survey](#kg-mm-survey)
  - [🔔 News](#-news)
  - [📜Content](#-content)
  - [🤖🌄 KG-driven Multi-modal Learning (KG4MM)](#-kg-driven-multi-modal-learning-kg4mm)
    - [Understanding & Reasoning Tasks](#understanding--reasoning-tasks)
      - [Visual Question Answering](#visual-question-answering)
      - [Visual Question Generation](#visual-question-generation)
      - [Visual Dialog](#visual-dialog)
    - [Classification Tasks](#classification-tasks)
      - [Image Classification](#image-classification)
      - [Fake News Detection](#fake-news-detection)
      - [Movie Genre Classification](#movie-genre-classification)
    - [Content Generation Tasks](#content-generation-tasks)
      - [Image Captioning](#image-captioning)
      - [Visual Storytelling](#visual-storytelling)
      - [Conditional Text-to-Image Generation](#conditional-text-to-image-generation)
      - [Scene Graph Generation](#scene-graph-generation)
    - [Retrieval Tasks](#retrieval-tasks)
      - [Cross-Modal Retrieval](#cross-modal-retrieval)
      - [Visual Referring Expressions & Grounding](#visual-referring-expressions--grounding)
    - [KG-aware Mutli-modal Pre-training](#kg-aware-mutli-modal-pre-training)
      - [Structure Knowledge aware Pre-training](#structure-knowledge-aware-pre-training)
      - [Knowledge Graph aware Pre-training](#knowledge-graph-aware-pre-training)
  - [🌄🤖 Multi-modal Knowledge Graph (MM4KG)](#-multi-modal-knowledge-graph-mm4kg)
    - [MMKG Resources](#mmkg-resources)
      - [A-MMKG](#a-mmkg)
      - [N-MMKG](#n-mmkg)
      - [Task-specific MMKG](#task-specific-mmkg)
    - [MMKG Acquisition](#mmkg-acquisition)
      - [Multi-modal Named Entity Recognition](#multi-modal-named-entity-recognition)
      - [Multi-modal Relation Extraction](#multi-modal-relation-extraction)
      - [Multi-modal Event Extraction](#multi-modal-event-extraction)
    - [MMKG Fusion](#mmkg-fusion)
      - [Multi-modal Entity Alignment](#multi-modal-entity-alignment)
      - [Multi-modal Entity Linking & Disambiguation](#multi-modal-entity-linking--disambiguation)
    - [MMKG Inference](#mmkg-inference)
      - [Multi-modal Knowledge Graph Completion](#multi-modal-knowledge-graph-completion)
      - [Multi-modal Knowledge Graphs Reasoning](#multi-modal-knowledge-graphs-reasoning)
    - [MMKG-driven Tasks](#mmkg-driven-tasks)
      - [Retrieval](#retrieval)
      - [Reasoning & Generation](#reasoning--generation)
      - [Pre-training](#pre-training)
      - [AI for Science](#ai-for-science)
      - [Industry Application](#industry-application)
  - [Contribution](#contribution)
    - [👥 Contributors](#-contributors)
    - [🔖 Contact](#-contact)
    - [🤝 Citation:](#-cite)

---

## 🤖🌄 KG-driven Multi-modal Learning (KG4MM)

### Understanding & Reasoning Tasks
<details>
   <summary>👈 🔎 Pipeline </summary>
   
![KG4MMR](figures/kg4mmr.jpg)

</details>

#### Visual Question Answering

<details>
    <summary>👈 🔎 Benchmarks </summary>

![VQA](figures/vqatab.jpg)

</details>

#### Visual Question Generation

#### Visual Dialog

### Classification Tasks
<details>
   <summary>👈 🔎 Comparison </summary>
   
![IMGC](figures/imgc.jpg)

</details>

#### Image Classification
<details>
    <summary>👈 🔎 Benchmarks </summary>

![IMG](figures/imgctab.jpg)

</details>

#### Fake News Detection

#### Movie Genre Classification

### Content Generation Tasks 
<details>
   <summary>👈 🔎 Case </summary>
   
![case](figures/VGG.jpg)

</details>

#### Image Captioning

#### Visual Storytelling

#### Conditional Text-to-Image Generation

#### Scene Graph Generation

### Retrieval Tasks
<details>
   <summary>👈 🔎 Case </summary>
   
![case](figures/CMR.jpg)

</details>

#### Cross-Modal Retrieval

#### Visual Referring Expressions & Grounding

### KG-aware Mutli-modal Pre-training

#### Structure Knowledge aware Pre-training

#### Knowledge Graph aware Pre-training

---

##  🌄🤖 Multi-modal Knowledge Graph (MM4KG)

<details>
    <summary>👈 🔎 MMKG Overview </summary>

![MMKG](figures/mmkgtab.jpg)

</details>

### MMKG Resources
- \[[arxiv](https://arxiv.org/abs/2401.14640)\] Benchmarking Large Language Models in Complex Question Answering Attribution using Knowledge Graphs. `2024.01`

#### A-MMKG

#### N-MMKG

<details>
    <summary>👈 🔎 N-MMKG Ontology </summary>

![MMKGOnto](figures/mmkgonto.jpg)

</details>



#### Task-specific MMKG

### MMKG Acquisition
<details>
   <summary>👈 🔎 Case </summary>
   
![case](figures/MMIE.jpg)

</details>

#### Multi-modal Named Entity Recognition
<details>
    <summary>👈 🔎 Benchmarks </summary>

![MNER](figures/mnertab.jpg)

</details>

#### Multi-modal Relation Extraction
<details>
    <summary>👈 🔎 Benchmarks </summary>

![MMRE](figures/mmretab.jpg)

</details>

#### Multi-modal Event Extraction
<details>
    <summary>👈 🔎 Benchmarks </summary>

![MMEE](figures/mmeetab.jpg)

</details>

### MMKG Fusion

#### Multi-modal Entity Alignment
<details>
    <summary>👈 🔎 Benchmarks </summary>

![MMEA](figures/mmeatab.jpg)

</details>

#### Multi-modal Entity Linking & Disambiguation
<details>
    <summary>👈 🔎 Benchmarks </summary>

![MMEL](figures/mmeltab.jpg)

</details>

### MMKG Inference

#### Multi-modal Knowledge Graph Completion
<details>
    <summary>👈 🔎 Benchmarks </summary>

![MKGC](figures/mkgctab.jpg)

</details>

#### Multi-modal Knowledge Graphs Reasoning

### MMKG-driven Tasks
<details>
   <summary>👈 🔎 Case </summary>
   
![case](figures/mmkg4mm.jpg)

</details>

#### Retrieval

#### Reasoning & Generation

#### Pre-training

#### AI for Science

#### Industry Application






## Contribution
### 👥 Contributors

<a href="https://github.com/zjukg/KG-MM-Survey/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=zjukg/KG-MM-Survey" />
</a>

### 🎉 Contributing ( welcome ! )

- ✨ Add a new paper or update an existing KG-related LLM paper.
- 🧐 Use the same format as existing entries to describe the work.
- 😄 A very brief explanation why you think a paper should be added or updated is recommended (Not Neccessary) via **`Adding Issues`** or **`Pull Requests`**.

**Don't worry if you put something wrong, they will be fixed for you. Just feel free to contribute and promote your awesome work here! 🤩 We'll get back to you in time ~ 😉**

---

### 🔖 Contact

> 📫 How to reach me: zhuo.chen@zju.edu.cn 


### 🤝 Cite:
If this Repo is helpful to you, please consider citing our paper. We would greatly appreciate it :)
```bigquery
TODO
```

![Star History Chart](https://api.star-history.com/svg?repos=zjukg/KG-MM-Survey&type=Date)


